{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the results of the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils) # Reload instead of using cached version\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "\n",
    "# Make sure we're using python 3.10.1 (same as version on short)\n",
    "!python3 --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set root to git subfolder\n",
    "git_root = subprocess.check_output(['git', 'rev-parse', '--show-toplevel']).decode('utf-8').strip()\n",
    "os.chdir(git_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_DIR = \"experiments/temp_results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first extract all the experiments and trial (folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_root_name = lambda path : path.split(\"/\")[-2]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Loop through all the search algorithms\n",
    "search_algorithms = glob.glob(RESULT_DIR + \"/*/\")\n",
    "for search_algorithm in search_algorithms:\n",
    "    rl_algorithms = glob.glob(search_algorithm + \"/*/\")\n",
    "    for rl_algorithm in rl_algorithms:\n",
    "        trial_numbers = glob.glob(rl_algorithm + \"/*/\")\n",
    "        for trial_number in trial_numbers:\n",
    "            path_log = trial_number + \"logs/\"\n",
    "            new_row = pd.DataFrame([{\"search_algorithm\": get_root_name(search_algorithm), \"rl_algorithm\": get_root_name(rl_algorithm), \"trial_number\": get_root_name(trial_number).split(\"_\")[-1], \"path_log\": path_log}])\n",
    "            df = pd.concat([df, new_row], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns in tvec.csv: \n",
    "# algo_name,algo_name_nice,scenario_name,scenario_name_nice,seed,k,patch,patch_clean,patch_valid,diff,diff_valid,stats_steps,stats_steps_useful,stats_steps_useful_105,log_time_search,log_time_validation,log_time_test,log_time_valid_test,log_time_all,log_time_valid_all,fit_search,fit_training,fit_validation,fit_test,fit_all,fit_valid_training,fit_valid_validation,fit_valid_test,fit_valid_all,fit_init_search,fit_init_training,fit_init_validation,fit_init_test,fit_init_all,fit_init_valid_training,fit_init_valid_validation,fit_init_valid_test,fit_init_valid_all,runtime_test,runtime_all,runtime_valid_test,runtime_valid_all,runtime_init_test,runtime_init_all,runtime_init_valid_test,runtime_init_valid_all,patch_size,patch_clean_size,patch_valid_size,ratio_fit_search,ratio_fit_training,ratio_fit_validation,ratio_fit_test,ratio_fit_all,ratio_fit_valid_training,ratio_fit_valid_validation,ratio_fit_valid_test,ratio_fit_valid_all,ratio_runtime_test,ratio_runtime_all,ratio_runtime_valid_test,ratio_runtime_valid_all,ratio_steps_useful,ratio_steps_useful_105\n",
    "# TODO: stats_steps,stats_steps_useful,stats_steps_useful_105,log_time_search,log_time_validation,log_time_test,log_time_valid_test,log_time_all,log_time_valid_all,fit_search,fit_training,fit_validation,fit_test,fit_all,fit_valid_training,fit_valid_validation,fit_valid_test,fit_valid_all,fit_init_search,fit_init_training,fit_init_validation,fit_init_test,fit_init_all,fit_init_valid_training,fit_init_valid_validation,fit_init_valid_test,fit_init_valid_all,runtime_test,runtime_all,runtime_valid_test,runtime_valid_all,runtime_init_test,runtime_init_all,runtime_init_valid_test,runtime_init_valid_all,patch_size,patch_clean_size,patch_valid_size,ratio_fit_search,ratio_fit_training,ratio_fit_validation,ratio_fit_test,ratio_fit_all,ratio_fit_valid_training,ratio_fit_valid_validation,ratio_fit_valid_test,ratio_fit_valid_all,ratio_runtime_test,ratio_runtime_all,ratio_runtime_valid_test,ratio_runtime_valid_all,ratio_steps_useful,ratio_steps_useful_105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Pickle Object\n",
    "df['pkl_obj'] = df['path_log'].apply(utils.generate_pickle_object)\n",
    "df['pkl_obj'].iloc[0] # Example of what the pickle object looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract some common columns we might need\n",
    "\n",
    "# df['seed'] = df['pkl_obj'].apply(lambda x: x['seed'])\n",
    "df['diff'] = df['pkl_obj'].apply(lambda x: x['diff'])\n",
    "df['initial_fitness'] = df['pkl_obj'].apply(lambda x: x['initial_fitness'])\n",
    "df['best_fitness'] = df['pkl_obj'].apply(lambda x: x['best_fitness'])\n",
    "df['patch'] = df['path_log'].apply(utils.get_patch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warmup Consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we explore the variance of the warmup phase. For our experiment, we used to perf function in hopes of minimizing the variance of the warmup phase. The hope is that the variance of the warmup phase is small enough that we can ignore it. We will explore this assumption here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mean_warmup_fitness'] = df['pkl_obj'].apply(lambda x: np.mean(x['warmup_values']))\n",
    "df['std_warmup_fitness'] = df['pkl_obj'].apply(lambda x: np.std(x['warmup_values']))\n",
    "df['coeff_of_variation_warmup_fitness'] = df['std_warmup_fitness'] / df['mean_warmup_fitness']\n",
    "df['coeff_of_variation_warmup_fitness'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magpie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
